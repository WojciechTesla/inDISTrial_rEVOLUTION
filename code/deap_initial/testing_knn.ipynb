{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d98a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d2ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def garbo_distance(x, y):\n",
    "    \"\"\"\n",
    "    Custom distance function for KNN.\n",
    "    \"\"\"\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82252218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "X = [[1,1],[0,0],[1,1],[1,1],[1,1]]\n",
    "y = [1, 1, 0, 0, 0]\n",
    "knn = KNeighborsClassifier(n_neighbors=5, metric=garbo_distance)\n",
    "knn.fit(X, y)\n",
    "print(knn.predict([[0, 0], [1, 1]]))  # Should print [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e7ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa9e4f72",
   "metadata": {},
   "source": [
    "# Testing Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbc468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import os\n",
    "import random\n",
    "from deap import algorithms, base, creator, tools, gp\n",
    "import operator\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, silhouette_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, make_scorer\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris, load_wine, fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import time\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f544599",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'warnings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Suppress warnings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mwarnings\u001b[49m.filterwarnings(\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMetricEvaluator\u001b[39;00m:\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    Framework for evaluating different distance metrics with various classifiers.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'warnings' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MetricEvaluator:\n",
    "    \"\"\"\n",
    "    Framework for evaluating different distance metrics with various classifiers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        \"\"\"Initialize the evaluator with a random state for reproducibility.\"\"\"\n",
    "        self.random_state = random_state\n",
    "        self.results = {}\n",
    "        self.models = {}\n",
    "        self.metrics = {}\n",
    "        self.datasets = {}\n",
    "        self.transformers = {}\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.results_dir = \"evaluation_results\"\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "        \n",
    "    def add_dataset(self, name, X, y, description=None):\n",
    "        \"\"\"Add a dataset to the evaluator.\"\"\"\n",
    "        self.datasets[name] = {\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "            'description': description or name\n",
    "        }\n",
    "        print(f\"Added dataset: {name} with shape {X.shape}\")\n",
    "        return self\n",
    "        \n",
    "    def load_standard_dataset(self, dataset_name):\n",
    "        \"\"\"Load one of the standard datasets.\"\"\"\n",
    "        if dataset_name.lower() == 'iris':\n",
    "            data = load_iris()\n",
    "            X, y = data.data, data.target\n",
    "            description = \"Iris Dataset\"\n",
    "        elif dataset_name.lower() == 'wine':\n",
    "            data = load_wine()\n",
    "            X, y = data.data, data.target\n",
    "            description = \"Wine Dataset\"\n",
    "        elif dataset_name.lower() == 'banknote':\n",
    "            data = fetch_openml(name='banknote-authentication', version=1, as_frame=False)\n",
    "            X, y = data.data, data.target.astype(int)\n",
    "            description = \"Banknote Authentication Dataset\"\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset {dataset_name} not recognized\")\n",
    "            \n",
    "        self.add_dataset(dataset_name, X, y, description)\n",
    "        return self\n",
    "\n",
    "    def prepare_data(self, dataset_name, test_size=0.2, scale=True):\n",
    "        \"\"\"Prepare the data by splitting and optionally scaling.\"\"\"\n",
    "        if dataset_name not in self.datasets:\n",
    "            raise ValueError(f\"Dataset {dataset_name} not found. Add it first with add_dataset().\")\n",
    "            \n",
    "        X = self.datasets[dataset_name]['X']\n",
    "        y = self.datasets[dataset_name]['y']\n",
    "        \n",
    "        # Split the data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Scale if needed\n",
    "        if scale:\n",
    "            scaler = StandardScaler()\n",
    "            self.X_train = scaler.fit_transform(self.X_train)\n",
    "            self.X_test = scaler.transform(self.X_test)\n",
    "            self.transformers['scaler'] = scaler\n",
    "            \n",
    "        print(f\"Data prepared: X_train {self.X_train.shape}, X_test {self.X_test.shape}\")\n",
    "        self.current_dataset = dataset_name\n",
    "        return self\n",
    "        \n",
    "    def add_standard_metrics(self):\n",
    "        \"\"\"Add standard distance metrics for comparison.\"\"\"\n",
    "        # Basic metrics\n",
    "        self.add_metric('euclidean', lambda X, Y=None: euclidean_distances(X, Y))\n",
    "        self.add_metric('cosine', lambda X, Y=None: cosine_distances(X, Y))\n",
    "        \n",
    "        # Add Mahalanobis with identity matrix (equivalent to Euclidean)\n",
    "        def mahalanobis_identity(X, Y=None):\n",
    "            n_features = X.shape[1]\n",
    "            M = np.eye(n_features)\n",
    "            return self._mahalanobis_distance(X, Y, M)\n",
    "        \n",
    "        self.add_metric('mahalanobis_identity', mahalanobis_identity)\n",
    "        \n",
    "        print(\"Added standard metrics: euclidean, cosine, mahalanobis_identity\")\n",
    "        return self\n",
    "        \n",
    "    def add_ml_metrics(self):\n",
    "        \"\"\"Add metric learning based distance metrics.\"\"\"\n",
    "        # LMNN (Large Margin Nearest Neighbor)\n",
    "        if self.X_train is None:\n",
    "            raise ValueError(\"Data must be prepared first using prepare_data()\")\n",
    "            \n",
    "        print(\"Training LMNN metric...\")\n",
    "        lmnn = LMNN(k=3, random_state=self.random_state)\n",
    "        lmnn.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        def lmnn_distance(X, Y=None):\n",
    "            X_transformed = lmnn.transform(X)\n",
    "            if Y is None:\n",
    "                Y_transformed = X_transformed\n",
    "            else:\n",
    "                Y_transformed = lmnn.transform(Y)\n",
    "            return euclidean_distances(X_transformed, Y_transformed)\n",
    "            \n",
    "        self.add_metric('lmnn', lmnn_distance)\n",
    "        self.transformers['lmnn'] = lmnn\n",
    "        \n",
    "        # NCA (Neighborhood Components Analysis)\n",
    "        print(\"Training NCA metric...\")\n",
    "        nca = NeighborhoodComponentsAnalysis(random_state=self.random_state)\n",
    "        nca.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        def nca_distance(X, Y=None):\n",
    "            X_transformed = nca.transform(X)\n",
    "            if Y is None:\n",
    "                Y_transformed = X_transformed\n",
    "            else:\n",
    "                Y_transformed = nca.transform(Y)\n",
    "            return euclidean_distances(X_transformed, Y_transformed)\n",
    "            \n",
    "        self.add_metric('nca', nca_distance)\n",
    "        self.transformers['nca'] = nca\n",
    "        \n",
    "        print(\"Added ML metrics: lmnn, nca\")\n",
    "        return self\n",
    "        \n",
    "    def add_custom_metric(self, name, distance_fn, transformer=None):\n",
    "        \"\"\"Add a custom distance metric.\"\"\"\n",
    "        self.add_metric(name, distance_fn)\n",
    "        if transformer is not None:\n",
    "            self.transformers[name] = transformer\n",
    "        return self\n",
    "        \n",
    "    def add_evolved_mahalanobis(self, M):\n",
    "        \"\"\"Add an evolved Mahalanobis metric with the given matrix M.\"\"\"\n",
    "        def evolved_mahalanobis(X, Y=None):\n",
    "            return self._mahalanobis_distance(X, Y, M)\n",
    "            \n",
    "        self.add_metric('evolved_mahalanobis', evolved_mahalanobis)\n",
    "        self.transformers['evolved_mahalanobis_matrix'] = M\n",
    "        return self\n",
    "        \n",
    "    def _mahalanobis_distance(self, X, Y=None, M=None):\n",
    "        \"\"\"Calculate Mahalanobis distance with matrix M.\"\"\"\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "            \n",
    "        n_samples_X = X.shape[0]\n",
    "        n_samples_Y = Y.shape[0]\n",
    "        distances = np.zeros((n_samples_X, n_samples_Y))\n",
    "        \n",
    "        for i in range(n_samples_X):\n",
    "            for j in range(n_samples_Y):\n",
    "                diff = X[i] - Y[j]\n",
    "                distances[i, j] = np.sqrt(diff.dot(M).dot(diff))\n",
    "                \n",
    "        return distances\n",
    "        \n",
    "    def add_metric(self, name, distance_fn):\n",
    "        \"\"\"Add a distance metric to the evaluator.\"\"\"\n",
    "        self.metrics[name] = distance_fn\n",
    "        print(f\"Added metric: {name}\")\n",
    "        return self\n",
    "        \n",
    "    def evaluate_classifier(self, clf_name, clf, metric_name, cv=5):\n",
    "        \"\"\"Evaluate a single classifier with a specific metric.\"\"\"\n",
    "        if self.X_train is None:\n",
    "            raise ValueError(\"Data must be prepared first using prepare_data()\")\n",
    "            \n",
    "        if metric_name not in self.metrics:\n",
    "            raise ValueError(f\"Metric {metric_name} not found\")\n",
    "            \n",
    "        distance_fn = self.metrics[metric_name]\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # For KNN, we need to use the custom metric\n",
    "        if clf_name == 'k-NN':\n",
    "            # For KNN, we need to modify the classifier to use our distance function\n",
    "            if isinstance(clf, KNeighborsClassifier):\n",
    "                def custom_metric(x, y):\n",
    "                    return distance_fn(x.reshape(1, -1), y.reshape(1, -1))[0][0]\n",
    "                \n",
    "                clf = KNeighborsClassifier(\n",
    "                    n_neighbors=clf.n_neighbors,\n",
    "                    metric=custom_metric,\n",
    "                    algorithm='brute'  # Required for custom metrics\n",
    "                )\n",
    "        \n",
    "        # For SVM with custom kernel\n",
    "        elif clf_name == 'SVM':\n",
    "            if isinstance(clf, SVC) and clf.kernel == 'precomputed':\n",
    "                # Compute the kernel matrix\n",
    "                dist_matrix = distance_fn(self.X_train)\n",
    "                # Convert distance to similarity using RBF transformation\n",
    "                gamma = 1.0 / self.X_train.shape[1]  # Default gamma\n",
    "                kernel_matrix = np.exp(-gamma * dist_matrix)\n",
    "                \n",
    "                # Train the SVM with the precomputed kernel\n",
    "                clf.fit(kernel_matrix, self.y_train)\n",
    "                \n",
    "                # Compute test kernel matrix\n",
    "                test_dist_matrix = distance_fn(self.X_test, self.X_train)\n",
    "                test_kernel_matrix = np.exp(-gamma * test_dist_matrix)\n",
    "                \n",
    "                # Predict using the test kernel matrix\n",
    "                y_pred = clf.predict(test_kernel_matrix)\n",
    "                test_acc = accuracy_score(self.y_test, y_pred)\n",
    "                \n",
    "                # Cross-validation for SVM with precomputed kernel is complex\n",
    "                # We'll use a simpler approach for CV with precomputed kernels\n",
    "                cv_scores = []\n",
    "                skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=self.random_state)\n",
    "                \n",
    "                for train_idx, val_idx in skf.split(self.X_train, self.y_train):\n",
    "                    X_cv_train, X_cv_val = self.X_train[train_idx], self.X_train[val_idx]\n",
    "                    y_cv_train, y_cv_val = self.y_train[train_idx], self.y_train[val_idx]\n",
    "                    \n",
    "                    # Compute kernel matrices for this fold\n",
    "                    cv_dist_matrix = distance_fn(X_cv_train)\n",
    "                    cv_kernel_matrix = np.exp(-gamma * cv_dist_matrix)\n",
    "                    \n",
    "                    cv_model = SVC(kernel='precomputed', random_state=self.random_state)\n",
    "                    cv_model.fit(cv_kernel_matrix, y_cv_train)\n",
    "                    \n",
    "                    val_dist_matrix = distance_fn(X_cv_val, X_cv_train)\n",
    "                    val_kernel_matrix = np.exp(-gamma * val_dist_matrix)\n",
    "                    \n",
    "                    val_pred = cv_model.predict(val_kernel_matrix)\n",
    "                    cv_scores.append(accuracy_score(y_cv_val, val_pred))\n",
    "                \n",
    "                cv_acc = np.mean(cv_scores)\n",
    "                \n",
    "                results = {\n",
    "                    'test_accuracy': test_acc,\n",
    "                    'cv_accuracy': cv_acc,\n",
    "                    'training_time': time.time() - start_time,\n",
    "                    'confusion_matrix': confusion_matrix(self.y_test, y_pred),\n",
    "                    'classification_report': classification_report(self.y_test, y_pred, output_dict=True)\n",
    "                }\n",
    "                \n",
    "                # Try to compute silhouette score (may fail for some distance metrics)\n",
    "                try:\n",
    "                    # Calculate distance matrix for silhouette\n",
    "                    dist_matrix_all = distance_fn(self.X_test)\n",
    "                    # Convert distances to a condensed form required by silhouette_score\n",
    "                    condensed_distances = squareform(dist_matrix_all)\n",
    "                    s_score = silhouette_score(\n",
    "                        X=None, \n",
    "                        labels=self.y_test, \n",
    "                        metric='precomputed', \n",
    "                        precomputed_distances=condensed_distances\n",
    "                    )\n",
    "                    results['silhouette_score'] = s_score\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not calculate silhouette score: {e}\")\n",
    "                    results['silhouette_score'] = None\n",
    "                \n",
    "                model_key = f\"{self.current_dataset}_{clf_name}_{metric_name}\"\n",
    "                self.models[model_key] = clf\n",
    "                \n",
    "                # Store results\n",
    "                if self.current_dataset not in self.results:\n",
    "                    self.results[self.current_dataset] = {}\n",
    "                if clf_name not in self.results[self.current_dataset]:\n",
    "                    self.results[self.current_dataset][clf_name] = {}\n",
    "                \n",
    "                self.results[self.current_dataset][clf_name][metric_name] = results\n",
    "                return results\n",
    "        \n",
    "        # For all other classifiers or non-precomputed SVM\n",
    "        # Fit the classifier\n",
    "        clf.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Get predictions\n",
    "        y_pred = clf.predict(self.X_test)\n",
    "        test_acc = accuracy_score(self.y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(clf, self.X_train, self.y_train, cv=cv, scoring='accuracy')\n",
    "        cv_acc = cv_scores.mean()\n",
    "        \n",
    "        results = {\n",
    "            'test_accuracy': test_acc,\n",
    "            'cv_accuracy': cv_acc,\n",
    "            'training_time': time.time() - start_time,\n",
    "            'confusion_matrix': confusion_matrix(self.y_test, y_pred),\n",
    "            'classification_report': classification_report(self.y_test, y_pred, output_dict=True)\n",
    "        }\n",
    "        \n",
    "        # Try to compute silhouette score\n",
    "        try:\n",
    "            # For standard metrics, we can directly compute silhouette\n",
    "            if metric_name in ['euclidean', 'cosine']:\n",
    "                s_score = silhouette_score(\n",
    "                    self.X_test, \n",
    "                    self.y_test, \n",
    "                    metric=metric_name.replace('_', '')\n",
    "                )\n",
    "            else:\n",
    "                # For custom metrics, we need to precompute the distance matrix\n",
    "                dist_matrix = distance_fn(self.X_test)\n",
    "                # Ensure the matrix is symmetric for silhouette calculation\n",
    "                if not np.allclose(dist_matrix, dist_matrix.T):\n",
    "                    dist_matrix = (dist_matrix + dist_matrix.T) / 2\n",
    "                # Convert to condensed form\n",
    "                condensed_distances = squareform(dist_matrix)\n",
    "                s_score = silhouette_score(\n",
    "                    X=None, \n",
    "                    labels=self.y_test, \n",
    "                    metric='precomputed', \n",
    "                    precomputed_distances=condensed_distances\n",
    "                )\n",
    "            results['silhouette_score'] = s_score\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not calculate silhouette score: {e}\")\n",
    "            results['silhouette_score'] = None\n",
    "            \n",
    "        # Store the model\n",
    "        model_key = f\"{self.current_dataset}_{clf_name}_{metric_name}\"\n",
    "        self.models[model_key] = clf\n",
    "        \n",
    "        # Store results\n",
    "        if self.current_dataset not in self.results:\n",
    "            self.results[self.current_dataset] = {}\n",
    "        if clf_name not in self.results[self.current_dataset]:\n",
    "            self.results[self.current_dataset][clf_name] = {}\n",
    "            \n",
    "        self.results[self.current_dataset][clf_name][metric_name] = results\n",
    "        return results\n",
    "        \n",
    "    def evaluate_all_classifiers(self, metric_names=None):\n",
    "        \"\"\"Evaluate all standard classifiers with specified metrics.\"\"\"\n",
    "        if self.X_train is None:\n",
    "            raise ValueError(\"Data must be prepared first using prepare_data()\")\n",
    "            \n",
    "        if metric_names is None:\n",
    "            metric_names = list(self.metrics.keys())\n",
    "            \n",
    "        # Define the classifiers\n",
    "        classifiers = {\n",
    "            'k-NN': KNeighborsClassifier(n_neighbors=3),\n",
    "            'SVM': SVC(kernel='precomputed', random_state=self.random_state),\n",
    "            'Decision Tree': DecisionTreeClassifier(random_state=self.random_state)\n",
    "        }\n",
    "        \n",
    "        all_results = {}\n",
    "        \n",
    "        for clf_name, clf in classifiers.items():\n",
    "            all_results[clf_name] = {}\n",
    "            for metric_name in metric_names:\n",
    "                print(f\"Evaluating {clf_name} with {metric_name} metric...\")\n",
    "                result = self.evaluate_classifier(clf_name, clf, metric_name)\n",
    "                all_results[clf_name][metric_name] = result\n",
    "                \n",
    "        return all_results\n",
    "        \n",
    "    def summarize_results(self, output_format='dataframe'):\n",
    "        \"\"\"Summarize the evaluation results.\"\"\"\n",
    "        if not self.results:\n",
    "            raise ValueError(\"No evaluation results available. Run evaluate_classifier() first.\")\n",
    "            \n",
    "        summary = []\n",
    "        \n",
    "        for dataset_name, dataset_results in self.results.items():\n",
    "            for clf_name, clf_results in dataset_results.items():\n",
    "                for metric_name, metrics in clf_results.items():\n",
    "                    row = {\n",
    "                        'Dataset': dataset_name,\n",
    "                        'Classifier': clf_name,\n",
    "                        'Metric': metric_name,\n",
    "                        'Test Accuracy': metrics.get('test_accuracy', None),\n",
    "                        'CV Accuracy': metrics.get('cv_accuracy', None),\n",
    "                        'Silhouette Score': metrics.get('silhouette_score', None),\n",
    "                        'Training Time (s)': metrics.get('training_time', None)\n",
    "                    }\n",
    "                    summary.append(row)\n",
    "                    \n",
    "        if output_format.lower() == 'dataframe':\n",
    "            return pd.DataFrame(summary)\n",
    "        else:\n",
    "            return summary\n",
    "            \n",
    "    def plot_results(self, dataset_name=None, metric='test_accuracy', figsize=(12, 6)):\n",
    "        \"\"\"Plot the evaluation results.\"\"\"\n",
    "        if not self.results:\n",
    "            raise ValueError(\"No evaluation results available. Run evaluate_classifier() first.\")\n",
    "            \n",
    "        if dataset_name is None:\n",
    "            if self.current_dataset:\n",
    "                dataset_name = self.current_dataset\n",
    "            else:\n",
    "                dataset_name = list(self.results.keys())[0]\n",
    "                \n",
    "        dataset_results = self.results.get(dataset_name, None)\n",
    "        if dataset_results is None:\n",
    "            raise ValueError(f\"No results for dataset {dataset_name}\")\n",
    "            \n",
    "        # Create a dataframe for plotting\n",
    "        plot_data = []\n",
    "        for clf_name, clf_results in dataset_results.items():\n",
    "            for metric_name, metrics in clf_results.items():\n",
    "                value = metrics.get(metric, None)\n",
    "                if value is not None:\n",
    "                    plot_data.append({\n",
    "                        'Classifier': clf_name,\n",
    "                        'Metric': metric_name,\n",
    "                        metric: value\n",
    "                    })\n",
    "                    \n",
    "        df = pd.DataFrame(plot_data)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=figsize)\n",
    "        ax = sns.barplot(x='Classifier', y=metric, hue='Metric', data=df)\n",
    "        \n",
    "        plt.title(f'{metric.replace(\"_\", \" \").title()} for {dataset_name}')\n",
    "        plt.xlabel('Classifier')\n",
    "        plt.ylabel(metric.replace('_', ' ').title())\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title='Distance Metric')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        plot_path = os.path.join(self.results_dir, f\"{dataset_name}_{metric}_{timestamp}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        print(f\"Plot saved to {plot_path}\")\n",
    "        \n",
    "        return ax\n",
    "        \n",
    "    def visualize_data_transformation(self, metric_name, method='tsne', figsize=(12, 10)):\n",
    "        \"\"\"Visualize how a metric transforms the data space.\"\"\"\n",
    "        if self.X_train is None:\n",
    "            raise ValueError(\"Data must be prepared first using prepare_data()\")\n",
    "            \n",
    "        if metric_name not in self.metrics and metric_name not in self.transformers:\n",
    "            raise ValueError(f\"Metric or transformer {metric_name} not found\")\n",
    "            \n",
    "        # Get transformer if available\n",
    "        transformer = self.transformers.get(metric_name, None)\n",
    "        \n",
    "        # If we have a direct transformer (like NCA or LMNN)\n",
    "        if transformer and hasattr(transformer, 'transform'):\n",
    "            X_transformed = transformer.transform(self.X_test)\n",
    "        # If we only have a distance function\n",
    "        elif metric_name in self.metrics:\n",
    "            # Compute distance matrix\n",
    "            distance_fn = self.metrics[metric_name]\n",
    "            dist_matrix = distance_fn(self.X_test)\n",
    "            \n",
    "            # Use t-SNE or PCA to visualize the distance matrix\n",
    "            if method.lower() == 'tsne':\n",
    "                embedding = TSNE(\n",
    "                    n_components=2, \n",
    "                    metric='precomputed',\n",
    "                    random_state=self.random_state\n",
    "                ).fit_transform(dist_matrix)\n",
    "                X_transformed = embedding\n",
    "            else:  # PCA\n",
    "                embedding = PCA(\n",
    "                    n_components=2,\n",
    "                    random_state=self.random_state\n",
    "                ).fit_transform(dist_matrix)\n",
    "                X_transformed = embedding\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot visualize {metric_name} - no transformer or distance function available\")\n",
    "            \n",
    "        # Cap to 2 dimensions for visualization\n",
    "        if X_transformed.shape[1] > 2:\n",
    "            if method.lower() == 'tsne':\n",
    "                X_transformed = TSNE(\n",
    "                    n_components=2,\n",
    "                    random_state=self.random_state\n",
    "                ).fit_transform(X_transformed)\n",
    "            else:  # PCA\n",
    "                X_transformed = PCA(\n",
    "                    n_components=2,\n",
    "                    random_state=self.random_state\n",
    "                ).fit_transform(X_transformed)\n",
    "                \n",
    "        # Plot\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # Get unique classes\n",
    "        unique_classes = np.unique(self.y_test)\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, len(unique_classes)))\n",
    "        \n",
    "        for i, class_val in enumerate(unique_classes):\n",
    "            idx = self.y_test == class_val\n",
    "            plt.scatter(\n",
    "                X_transformed[idx, 0], \n",
    "                X_transformed[idx, 1],\n",
    "                color=colors[i],\n",
    "                label=f'Class {class_val}',\n",
    "                alpha=0.7\n",
    "            )\n",
    "            \n",
    "        plt.title(f'Data Transformation using {metric_name} visualized with {method}')\n",
    "        plt.xlabel('Component 1')\n",
    "        plt.ylabel('Component 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Save the plot\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        plot_path = os.path.join(\n",
    "            self.results_dir, \n",
    "            f\"{self.current_dataset}_{metric_name}_{method}_{timestamp}.png\"\n",
    "        )\n",
    "        plt.savefig(plot_path)\n",
    "        print(f\"Visualization saved to {plot_path}\")\n",
    "        \n",
    "        return plt\n",
    "        \n",
    "    def save_results(self, filename=None):\n",
    "        \"\"\"Save the evaluation results to a file.\"\"\"\n",
    "        if not self.results:\n",
    "            raise ValueError(\"No evaluation results available. Run evaluate_classifier() first.\")\n",
    "            \n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = os.path.join(self.results_dir, f\"evaluation_results_{timestamp}.pkl\")\n",
    "            \n",
    "        # Create a results dictionary\n",
    "        results_dict = {\n",
    "            'results': self.results,\n",
    "            'dataset_names': list(self.datasets.keys()),\n",
    "            'metric_names': list(self.metrics.keys()),\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Save the results\n",
    "        joblib.dump(results_dict, filename)\n",
    "        print(f\"Results saved to {filename}\")\n",
    "        \n",
    "        # Also save as CSV for easy viewing\n",
    "        csv_filename = os.path.splitext(filename)[0] + '.csv'\n",
    "        summary_df = self.summarize_results()\n",
    "        summary_df.to_csv(csv_filename, index=False)\n",
    "        print(f\"Summary saved to {csv_filename}\")\n",
    "        \n",
    "        return filename\n",
    "        \n",
    "    def load_results(self, filename):\n",
    "        \"\"\"Load evaluation results from a file.\"\"\"\n",
    "        loaded_data = joblib.load(filename)\n",
    "        self.results = loaded_data['results']\n",
    "        print(f\"Loaded results from {filename}\")\n",
    "        return self\n",
    "        \n",
    "    def fisher_criterion(self, X, y):\n",
    "        \"\"\"Calculate Fisher's criterion for feature discriminative power.\n",
    "        \n",
    "        Higher values indicate better class separation.\n",
    "        \"\"\"\n",
    "        # Get unique classes\n",
    "        classes = np.unique(y)\n",
    "        n_classes = len(classes)\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Calculate global mean\n",
    "        global_mean = np.mean(X, axis=0)\n",
    "        \n",
    "        # Calculate between-class scatter matrix\n",
    "        S_b = np.zeros((n_features, n_features))\n",
    "        for c in classes:\n",
    "            X_c = X[y == c]\n",
    "            mean_c = np.mean(X_c, axis=0)\n",
    "            n_c = X_c.shape[0]\n",
    "            \n",
    "            # Update between-class scatter\n",
    "            mean_diff = mean_c - global_mean\n",
    "            S_b += n_c * np.outer(mean_diff, mean_diff)\n",
    "            \n",
    "        # Calculate within-class scatter matrix\n",
    "        S_w = np.zeros((n_features, n_features))\n",
    "        for c in classes:\n",
    "            X_c = X[y == c]\n",
    "            mean_c = np.mean(X_c, axis=0)\n",
    "            \n",
    "            # Center the data\n",
    "            X_c_centered = X_c - mean_c\n",
    "            \n",
    "            # Update within-class scatter\n",
    "            S_w += X_c_centered.T @ X_c_centered\n",
    "            \n",
    "        # Calculate Fisher's criterion (trace ratio)\n",
    "        try:\n",
    "            # Add small regularization to avoid singularity\n",
    "            S_w_reg = S_w + np.eye(n_features) * 1e-10\n",
    "            fisher_score = np.trace(np.linalg.inv(S_w_reg) @ S_b)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # If S_w is singular, use pseudoinverse\n",
    "            fisher_score = np.trace(np.linalg.pinv(S_w) @ S_b)\n",
    "            \n",
    "        return fisher_score\n",
    "        \n",
    "    def calculate_generalization_gap(self, clf_name, metric_name):\n",
    "        \"\"\"Calculate the generalization gap for a classifier-metric pair.\"\"\"\n",
    "        if self.current_dataset not in self.results:\n",
    "            raise ValueError(f\"No results for dataset {self.current_dataset}\")\n",
    "            \n",
    "        if clf_name not in self.results[self.current_dataset]:\n",
    "            raise ValueError(f\"No results for classifier {clf_name}\")\n",
    "            \n",
    "        if metric_name not in self.results[self.current_dataset][clf_name]:\n",
    "            raise ValueError(f\"No results for metric {metric_name}\")\n",
    "            \n",
    "        results = self.results[self.current_dataset][clf_name][metric_name]\n",
    "        \n",
    "        train_acc = results.get('train_accuracy', None)\n",
    "        test_acc = results.get('test_accuracy', None)\n",
    "        \n",
    "        if train_acc is None:\n",
    "            # Recompute train accuracy if not available\n",
    "            model_key = f\"{self.current_dataset}_{clf_name}_{metric_name}\"\n",
    "            model = self.models.get(model_key, None)\n",
    "            \n",
    "            if model is None:\n",
    "                raise ValueError(f\"Model for {model_key} not found\")\n",
    "                \n",
    "            y_train_pred = model.predict(self.X_train)\n",
    "            train_acc = accuracy_score(self.y_train, y_train_pred)\n",
    "            self.results[self.current_dataset][clf_name][metric_name]['train_accuracy'] = train_acc\n",
    "            \n",
    "        # Calculate generalization gap\n",
    "        gen_gap = train_acc - test_acc\n",
    "        self.results[self.current_dataset][clf_name][metric_name]['generalization_gap'] = gen_gap\n",
    "        \n",
    "        return gen_gap\n",
    "        \n",
    "    def estimate_model_complexity(self, clf_name, metric_name):\n",
    "        \"\"\"Estimate model complexity for a classifier-metric pair.\"\"\"\n",
    "        model_key = f\"{self.current_dataset}_{clf_name}_{metric_name}\"\n",
    "        model = self.models.get(model_key, None)\n",
    "        \n",
    "        if model is None:\n",
    "            raise ValueError(f\"Model for {model_key} not found\")\n",
    "            \n",
    "        complexity = None\n",
    "        \n",
    "        # For Decision Tree\n",
    "        if clf_name == 'Decision Tree':\n",
    "            complexity = model.get_n_leaves()\n",
    "            \n",
    "        # For k-NN, complexity is related to number of neighbors\n",
    "        elif clf_name == 'k-NN':\n",
    "            if hasattr(model, 'n_neighbors'):\n",
    "                complexity = 1 / model.n_neighbors  # Inverse of k (lower k = higher complexity)\n",
    "                \n",
    "        # For SVM, complexity is related to number of support vectors\n",
    "        elif clf_name == 'SVM':\n",
    "            if hasattr(model, 'support_vectors_'):\n",
    "                complexity = len(model.support_vectors_)\n",
    "                \n",
    "        if complexity is not None:\n",
    "            if self.current_dataset not in self.results:\n",
    "                self.results[self.current_dataset] = {}\n",
    "            if clf_name not in self.results[self.current_dataset]:\n",
    "                self.results[self.current_dataset][clf_name] = {}\n",
    "            if metric_name not in self.results[self.current_dataset][clf_name]:\n",
    "                self.results[self.current_dataset][clf_name][metric_name] = {}\n",
    "                \n",
    "            self.results[self.current_dataset][clf_name][metric_name]['complexity'] = complexity\n",
    "            \n",
    "        return complexity\n",
    "\n",
    "\n",
    "def load_additional_datasets():\n",
    "    \"\"\"Function to load additional datasets for comparison or transfer learning experiments.\"\"\"\n",
    "    datasets = {}\n",
    "    \n",
    "    try:\n",
    "        # Wine Quality - Red\n",
    "        red_wine = fetch_openml(name='wine-quality-red', version=1, as_frame=False)\n",
    "        datasets['red_wine'] = {\n",
    "            'X': red_wine.data, \n",
    "            'y': (red_wine.target > 5).astype(int),  # Binarize: good (>5) vs bad quality\n",
    "            'description': \"Wine Quality - Red\"\n",
    "        }\n",
    "        \n",
    "        # Wine Quality - White\n",
    "        white_wine = fetch_openml(name='wine-quality-white', version=1, as_frame=False)\n",
    "        datasets['white_wine'] = {\n",
    "            'X': white_wine.data,\n",
    "            'y': (white_wine.target > 5).astype(int),  # Binarize: good (>5) vs bad quality\n",
    "            'description': \"Wine Quality - White\"\n",
    "        }\n",
    "        \n",
    "        # Seeds Dataset\n",
    "        seeds = fetch_openml(name='seeds', version=1, as_frame=False)\n",
    "        datasets['seeds'] = {\n",
    "            'X': seeds.data,\n",
    "            'y': seeds.target.astype(int),\n",
    "            'description': \"Seeds Dataset\"\n",
    "        }\n",
    "        \n",
    "        # Heart Disease\n",
    "        heart = fetch_openml(name='heart-statlog', version=1, as_frame=False)\n",
    "        datasets['heart'] = {\n",
    "            'X': heart.data,\n",
    "            'y': heart.target.astype(int),\n",
    "            'description': \"Heart Disease (Statlog)\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load some datasets: {e}\")\n",
    "        \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MahalanobisEvolver:\n",
    "    \"\"\"\n",
    "    Class to evolve a Mahalanobis distance matrix using a genetic algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, y_train, random_state=42):\n",
    "        \"\"\"Initialize the evolver with training data.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.n_features = X_train.shape[1]\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "        random.seed(random_state)\n",
    "    \n",
    "    def _calculate_fisher_criterion(self, M):\n",
    "        \"\"\"\n",
    "        Calculate Fisher criterion for a given Mahalanobis matrix M.\n",
    "        Higher values indicate better class separation.\n",
    "        \"\"\"\n",
    "        # Transform data using the matrix\n",
    "        X_transformed = self.X_train @ np.linalg.cholesky(M)\n",
    "        \n",
    "        # Get unique classes\n",
    "        classes = np.unique(self.y_train)\n",
    "        n_classes = len(classes)\n",
    "        n_features = X_transformed.shape[1]\n",
    "        \n",
    "        # Calculate global mean\n",
    "        global_mean = np.mean(X_transformed, axis=0)\n",
    "        \n",
    "        # Calculate between-class scatter matrix\n",
    "        S_b = np.zeros((n_features, n_features))\n",
    "        for c in classes:\n",
    "            X_c = X_transformed[self.y_train == c]\n",
    "            mean_c = np.mean(X_c, axis=0)\n",
    "            n_c = X_c.shape[0]\n",
    "            \n",
    "            # Update between-class scatter\n",
    "            mean_diff = mean_c - global_mean\n",
    "            S_b += n_c * np.outer(mean_diff, mean_diff)\n",
    "            \n",
    "        # Calculate within-class scatter matrix\n",
    "        S_w = np.zeros((n_features, n_features))\n",
    "        for c in classes:\n",
    "            X_c = X_transformed[self.y_train == c]\n",
    "            mean_c = np.mean(X_c, axis=0)\n",
    "            \n",
    "            # Center the data\n",
    "            X_c_centered = X_c - mean_c\n",
    "            \n",
    "            # Update within-class scatter\n",
    "            S_w += X_c_centered.T @ X_c_centered\n",
    "            \n",
    "        # Calculate Fisher's criterion (trace ratio)\n",
    "        try:\n",
    "            # Add small regularization to avoid singularity\n",
    "            S_w_reg = S_w + np.eye(n_features) * 1e-10\n",
    "            fisher_score = np.trace(np.linalg.inv(S_w_reg) @ S_b)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # If S_w is singular, use pseudoinverse\n",
    "            fisher_score = np.trace(np.linalg.pinv(S_w) @ S_b)\n",
    "            \n",
    "        return fisher_score\n",
    "    \n",
    "    def _evaluate_individual(self, individual):\n",
    "        \"\"\"Fitness function for an individual (Mahalanobis matrix).\"\"\"\n",
    "        # Extract the diagonal and off-diagonal elements\n",
    "        diag_elements = np.array(individual[:self.n_features])\n",
    "        off_diag_elements = np.array(individual[self.n_features:])\n",
    "        \n",
    "        # Make sure diagonal elements are positive (PSD constraint)\n",
    "        diag_elements = np.abs(diag_elements)\n",
    "        \n",
    "        # Construct the symmetric matrix\n",
    "        M = np.zeros((self.n_features, self.n_features))\n",
    "        M[np.diag_indices(self.n_features)] = diag_elements\n",
    "        \n",
    "        # Fill the off-diagonal elements (upper triangular)\n",
    "        idx = 0\n",
    "        for i in range(self.n_features):\n",
    "            for j in range(i+1, self.n_features):\n",
    "                M[i, j] = off_diag_elements[idx]\n",
    "                M[j, i] = off_diag_elements[idx]  # Symmetry\n",
    "                idx += 1\n",
    "        \n",
    "        # Ensure the matrix is positive semi-definite\n",
    "        try:\n",
    "            # Add a small identity component for numerical stability\n",
    "            M = M + np.eye(self.n_features) * 1e-10\n",
    "            \n",
    "            # Calculate eigenvalues\n",
    "            eigvals = np.linalg.eigvalsh(M)\n",
    "            \n",
    "            # If any eigenvalue is negative, return low fitness\n",
    "            if np.any(eigvals < 0):\n",
    "                return -1000.0,\n",
    "                \n",
    "            # Calculate Fisher criterion\n",
    "            fisher_score = self._calculate_fisher_criterion(M)\n",
    "            \n",
    "            # Add regularization for simpler matrices (L1 norm of off-diagonals)\n",
    "            complexity_penalty = 0.01 * np.sum(np.abs(off_diag_elements))\n",
    "            \n",
    "            # Return fitness (higher is better)\n",
    "            return fisher_score - complexity_penalty,\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If there's any error, return low fitness\n",
    "            print(f\"Error in fitness calculation: {e}\")\n",
    "            return -2000.0,\n",
    "    \n",
    "    def evolve(self, n_generations=50, population_size=100, crossover_prob=0.7, \n",
    "               mutation_prob=0.2, tournsize=3, verbose=True):\n",
    "        \"\"\"\n",
    "        Evolve a Mahalanobis distance matrix using a genetic algorithm.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_generations : int\n",
    "            Number of generations to evolve\n",
    "        population_size : int\n",
    "            Size of the population\n",
    "        crossover_prob : float\n",
    "            Probability of crossover\n",
    "        mutation_prob : float\n",
    "            Probability of mutation\n",
    "        tournsize : int\n",
    "            Tournament size for selection\n",
    "        verbose : bool\n",
    "            Whether to print progress\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        best_matrix : numpy.ndarray\n",
    "            The best evolved Mahalanobis matrix\n",
    "        stats : dict\n",
    "            Evolution statistics\n",
    "        \"\"\"\n",
    "        # Total number of parameters in the Mahalanobis matrix\n",
    "        n_diag = self.n_features  # Diagonal elements\n",
    "        n_off_diag = self.n_features * (self.n_features - 1) // 2  # Off-diagonal elements\n",
    "        n_params = n_diag + n_off_diag\n",
    "        \n",
    "        # Set up the genetic algorithm\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        \n",
    "        toolbox = base.Toolbox()\n",
    "        \n",
    "        # Register gene initialization\n",
    "        toolbox.register(\"attr_float\", random.uniform, -1.0, 1.0)\n",
    "        \n",
    "        # Register individual and population initialization\n",
    "        toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                         toolbox.attr_float, n=n_params)\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        \n",
    "        # Register genetic operators\n",
    "        toolbox.register(\"evaluate\", self._evaluate_individual)\n",
    "        toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "        toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.5, indpb=0.2)\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=tournsize)\n",
    "        \n",
    "        # Create initial population\n",
    "        pop = toolbox.population(n=population_size)\n",
    "        \n",
    "        # Keep track of the best individual\n",
    "        hof = tools.HallOfFame(1)\n",
    "        \n",
    "        # Set up statistics\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean)\n",
    "        stats.register(\"std\", np.std)\n",
    "        stats.register(\"min\", np.min)\n",
    "        stats.register(\"max\", np.max)\n",
    "        \n",
    "        # Run the genetic algorithm\n",
    "        pop, logbook = algorithms.eaSimple(\n",
    "            pop, toolbox, cxpb=crossover_prob, mutpb=mutation_prob, \n",
    "            ngen=n_generations, stats=stats, halloffame=hof, verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Extract the best individual\n",
    "        best_individual = hof[0]\n",
    "        \n",
    "        # Convert the best individual to a Mahalanobis matrix\n",
    "        best_matrix = self._individual_to_matrix(best_individual)\n",
    "        \n",
    "        return best_matrix, logbook\n",
    "    \n",
    "    def _individual_to_matrix(self, individual):\n",
    "        \"\"\"Convert an individual to a Mahalanobis matrix.\"\"\"\n",
    "        # Extract the diagonal and off-diagonal elements\n",
    "        diag_elements = np.array(individual[:self.n_features])\n",
    "        off_diag_elements = np.array(individual[self.n_features:])\n",
    "        \n",
    "        # Make sure diagonal elements are positive (PSD constraint)\n",
    "        diag_elements = np.abs(diag_elements)\n",
    "        \n",
    "        # Construct the symmetric matrix\n",
    "        M = np.zeros((self.n_features, self.n_features))\n",
    "        M[np.diag_indices(self.n_features)] = diag_elements\n",
    "        \n",
    "        # Fill the off-diagonal elements (upper triangular)\n",
    "        idx = 0\n",
    "        for i in range(self.n_features):\n",
    "            for j in range(i+1, self.n_features):\n",
    "                M[i, j] = off_diag_elements[idx]\n",
    "                M[j, i] = off_diag_elements[idx]  # Symmetry\n",
    "                idx += 1\n",
    "        \n",
    "        # Ensure the matrix is positive semi-definite\n",
    "        # Add a small identity component for numerical stability\n",
    "        M = M + np.eye(self.n_features) * 1e-10\n",
    "        \n",
    "        return M\n",
    "    \n",
    "    def visualize_evolution(self, logbook, save_path=None):\n",
    "        \"\"\"Visualize the evolution progress.\"\"\"\n",
    "        gen = logbook.select(\"gen\")\n",
    "        fit_max = logbook.select(\"max\")\n",
    "        fit_avg = logbook.select(\"avg\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(gen, fit_max, \"b-\", label=\"Maximum Fitness\")\n",
    "        plt.plot(gen, fit_avg, \"r-\", label=\"Average Fitness\")\n",
    "        plt.title(\"Evolution of Fitness over Generations\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Fitness\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"Evolution plot saved to {save_path}\")\n",
    "        \n",
    "        return plt\n",
    "\n",
    "\n",
    "class SymbolicDistanceEvolver:\n",
    "    \"\"\"\n",
    "    Class to evolve symbolic distance metrics using Genetic Programming.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, y_train, random_state=42):\n",
    "        \"\"\"Initialize the evolver with training data.\"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.n_features = X_train.shape[1]\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "        random.seed(random_state)\n",
    "        \n",
    "        # Create feature terminals for GP\n",
    "        self.feature_names = [f\"x{i}\" for i in range(self.n_features)]\n",
    "        \n",
    "    def _eval_distance(self, individual, x1, x2):\n",
    "        \"\"\"Evaluate the distance function on two data points.\"\"\"\n",
    "        # Map feature names to values\n",
    "        feature_dict = {}\n",
    "        for i, name in enumerate(self.feature_names):\n",
    "            feature_dict[name + '1'] = x1[i]\n",
    "            feature_dict[name + '2'] = x2[i]\n",
    "        \n",
    "        # Add the difference for each feature\n",
    "        for i, name in enumerate(self.feature_names):\n",
    "            feature_dict['d' + name] = x1[i] - x2[i]\n",
    "            \n",
    "        # Compile the function\n",
    "        try:\n",
    "            # Convert individual to a string representation\n",
    "            func_str = str(individual)\n",
    "            \n",
    "            # Replace feature references\n",
    "            for name in self.feature_names:\n",
    "                func_str = func_str.replace(name, f\"feature_dict['{name}1']\")\n",
    "                func_str = func_str.replace(name, f\"feature_dict['{name}2']\")\n",
    "                func_str = func_str.replace('d' + name, f\"feature_dict['d{name}']\")\n",
    "                \n",
    "            # Evaluate the distance function\n",
    "            result = eval(func_str, {\n",
    "                \"protected_div\": self._protected_div,\n",
    "                \"protected_sqrt\": self._protected_sqrt,\n",
    "                \"protected_log\": self._protected_log,\n",
    "                \"feature_dict\": feature_dict,\n",
    "                \"abs\": abs,\n",
    "                \"max\": max,\n",
    "                \"min\": min\n",
    "            })\n",
    "            \n",
    "            # Distance should be non-negative\n",
    "            return max(0.0, float(result))\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If there's any error, return a large distance\n",
    "            return 1000.0\n",
    "            \n",
    "    def _protected_div(self, x, y):\n",
    "        \"\"\"Protected division to avoid division by zero.\"\"\"\n",
    "        if abs(y) < 1e-10:\n",
    "            return x\n",
    "        return x / y\n",
    "        \n",
    "    def _protected_sqrt(self, x):\n",
    "        \"\"\"Protected square root for negative numbers.\"\"\"\n",
    "        return math.sqrt(abs(x))\n",
    "        \n",
    "    def _protected_log(self, x):\n",
    "        \"\"\"Protected logarithm for non-positive numbers.\"\"\"\n",
    "        if x <= 0:\n",
    "            return 0\n",
    "        return math.log(x)\n",
    "        \n",
    "    def _calculate_distances(self, individual):\n",
    "        \"\"\"Calculate pairwise distances for all samples using the evolved function.\"\"\"\n",
    "        n_samples = len(self.X_train)\n",
    "        distances = np.zeros((n_samples, n_samples))\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            for j in range(i+1, n_samples):\n",
    "                dist = self._eval_distance(individual, self.X_train[i], self.X_train[j])\n",
    "                distances[i, j] = dist\n",
    "                distances[j, i] = dist  # Distance is symmetric\n",
    "                \n",
    "        return distances\n",
    "        \n",
    "    def _evaluate_individual(self, individual):\n",
    "        \"\"\"Fitness function for a symbolic distance function.\"\"\"\n",
    "        try:\n",
    "            # Calculate pairwise distances\n",
    "            distances = self._calculate_distances(individual)\n",
    "            \n",
    "            # Calculate silhouette score\n",
    "            try:\n",
    "                sil_score = silhouette_score(\n",
    "                    X=None, \n",
    "                    labels=self.y_train, \n",
    "                    metric='precomputed', \n",
    "                    precomputed_distances=distances\n",
    "                )\n",
    "            except:\n",
    "                # If silhouette calculation fails, use a proxy metric\n",
    "                # Calculate average distance between and within classes\n",
    "                classes = np.unique(self.y_train)\n",
    "                between_class_dists = []\n",
    "                within_class_dists = []\n",
    "                \n",
    "                for c1 in classes:\n",
    "                    idx1 = np.where(self.y_train == c1)[0]\n",
    "                    \n",
    "                    # Within-class distances\n",
    "                    for i in range(len(idx1)):\n",
    "                        for j in range(i+1, len(idx1)):\n",
    "                            within_class_dists.append(distances[idx1[i], idx1[j]])\n",
    "                    \n",
    "                    # Between-class distances\n",
    "                    for c2 in classes:\n",
    "                        if c1 != c2:\n",
    "                            idx2 = np.where(self.y_train == c2)[0]\n",
    "                            for i in idx1:\n",
    "                                for j in idx2:\n",
    "                                    between_class_dists.append(distances[i, j])\n",
    "                \n",
    "                # Calculate average distances\n",
    "                avg_within = np.mean(within_class_dists) if within_class_dists else 0\n",
    "                avg_between = np.mean(between_class_dists) if between_class_dists else 0\n",
    "                \n",
    "                # Fitness is the ratio of between/within (higher is better)\n",
    "                # Add small constant to avoid division by zero\n",
    "                sil_score = avg_between / (avg_within + 1e-10) - 1\n",
    "            \n",
    "            # Penalize complexity\n",
    "            complexity = len(str(individual))\n",
    "            complexity_penalty = 0.001 * complexity\n",
    "            \n",
    "            return sil_score - complexity_penalty,\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If there's any error, return low fitness\n",
    "            print(f\"Error in GP fitness calculation: {e}\")\n",
    "            return -10.0,\n",
    "            \n",
    "    def evolve(self, n_generations=50, population_size=100, crossover_prob=0.7,\n",
    "               mutation_prob=0.2, tournsize=3, verbose=True):\n",
    "        \"\"\"\n",
    "        Evolve a symbolic distance function using Genetic Programming.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_generations : int\n",
    "            Number of generations to evolve\n",
    "        population_size : int\n",
    "            Size of the population\n",
    "        crossover_prob : float\n",
    "            Probability of crossover\n",
    "        mutation_prob : float\n",
    "            Probability of mutation\n",
    "        tournsize : int\n",
    "            Tournament size for selection\n",
    "        verbose : bool\n",
    "            Whether to print progress\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        best_function : object\n",
    "            The best evolved distance function\n",
    "        stats : dict\n",
    "            Evolution statistics\n",
    "        \"\"\"\n",
    "        # Set up the genetic programming algorithm\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax)\n",
    "        \n",
    "        toolbox = base.Toolbox()\n",
    "        \n",
    "        # Define primitive set\n",
    "        pset = gp.PrimitiveSet(\"MAIN\", 0)\n",
    "        \n",
    "        # Add feature terminals\n",
    "        for i, name in enumerate(self.feature_names):\n",
    "            pset.addTerminal(name + '1')\n",
    "            pset.addTerminal(name + '2')\n",
    "            pset.addTerminal('d' + name)\n",
    "        \n",
    "        # Add constants\n",
    "        for const in [0.0, 0.5, 1.0, 2.0]:\n",
    "            pset.addTerminal(const)\n",
    "        \n",
    "        # Add operators\n",
    "        pset.addPrimitive(operator.add, 2)\n",
    "        pset.addPrimitive(operator.sub, 2)\n",
    "        pset.addPrimitive(operator.mul, 2)\n",
    "        pset.addPrimitive(self._protected_div, 2)\n",
    "        pset.addPrimitive(self._protected_sqrt, 1)\n",
    "        pset.addPrimitive(self._protected_log, 1)\n",
    "        pset.addPrimitive(abs, 1)\n",
    "        pset.addPrimitive(max, 2)\n",
    "        pset.addPrimitive(min, 2)\n",
    "        pset.addPrimitive(lambda x: x*x, 1, name=\"sqr\")\n",
    "        \n",
    "        # Register genetic operators\n",
    "        toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=4)\n",
    "        toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        toolbox.register(\"evaluate\", self._evaluate_individual)\n",
    "        toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "        toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "        toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
    "        toolbox.register(\"select\", tools.selTournament, tournsize=tournsize)\n",
    "        \n",
    "        # Create initial population\n",
    "        pop = toolbox.population(n=population_size)\n",
    "        \n",
    "        # Keep track of the best individual\n",
    "        hof = tools.HallOfFame(1)\n",
    "        \n",
    "        # Set up statistics\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"avg\", np.mean)\n",
    "        stats.register(\"std\", np.std)\n",
    "        stats.register(\"min\", np.min)\n",
    "        stats.register(\"max\", np.max)\n",
    "        \n",
    "        # Run the genetic programming algorithm\n",
    "        pop, logbook = algorithms.eaSimple(\n",
    "            pop, toolbox, cxpb=crossover_prob, mutpb=mutation_prob,\n",
    "            ngen=n_generations, stats=stats, halloffame=hof, verbose=verbose\n",
    "        )\n",
    "        \n",
    "        # Return the best individual and logbook\n",
    "        return hof[0], logbook\n",
    "    \n",
    "    def get_distance_function(self, individual):\n",
    "        \"\"\"Convert the evolved individual to a distance function.\"\"\"\n",
    "        def distance_function(X, Y=None):\n",
    "            if Y is None:\n",
    "                # Compute pairwise distances within X\n",
    "                n_samples = len(X)\n",
    "                distances = np.zeros((n_samples, n_samples))\n",
    "                \n",
    "                for i in range(n_samples):\n",
    "                    for j in range(i+1, n_samples):\n",
    "                        dist = self._eval_distance(individual, X[i], X[j])\n",
    "                        distances[i, j] = dist\n",
    "                        distances[j, i] = dist  # Distance is symmetric\n",
    "                        \n",
    "                return distances\n",
    "            else:\n",
    "                # Compute distances between X and Y\n",
    "                n_samples_X = len(X)\n",
    "                n_samples_Y = len(Y)\n",
    "                distances = np.zeros((n_samples_X, n_samples_Y))\n",
    "                \n",
    "                for i in range(n_samples_X):\n",
    "                    for j in range(n_samples_Y):\n",
    "                        distances[i, j] = self._eval_distance(individual, X[i], Y[j])\n",
    "                        \n",
    "                return distances\n",
    "                \n",
    "        return distance_function\n",
    "    \n",
    "    def visualize_evolution(self, logbook, save_path=None):\n",
    "        \"\"\"Visualize the evolution progress.\"\"\"\n",
    "        gen = logbook.select(\"gen\")\n",
    "        fit_max = logbook.select(\"max\")\n",
    "        fit_avg = logbook.select(\"avg\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(gen, fit_max, \"b-\", label=\"Maximum Fitness\")\n",
    "        plt.plot(gen, fit_avg, \"r-\", label=\"Average Fitness\")\n",
    "        plt.title(\"Evolution of Fitness over Generations\")\n",
    "        plt.xlabel(\"Generation\")\n",
    "        plt.ylabel(\"Fitness\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path)\n",
    "            print(f\"Evolution plot saved to {save_path}\")\n",
    "        \n",
    "        return plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example of evolving distance metrics.\n",
    "    \"\"\"\n",
    "    print(\"========== Distance Metric Evolution Demo ==========\")\n",
    "    \n",
    "    # 1. Load a dataset\n",
    "    print(\"\\n1. Loading the Iris dataset...\")\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    \n",
    "    # Split into train and test\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale the data\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # 2. Evolve a Mahalanobis distance metric\n",
    "    print(\"\\n2. Evolving a Mahalanobis distance metric...\")\n",
    "    mahalanobis_evolver = MahalanobisEvolver(X_train, y_train, random_state=42)\n",
    "    evolved_matrix, logbook = mahalanobis_evolver.evolve(\n",
    "        n_generations=20,  # Small number for demo purposes\n",
    "        population_size=50,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    # Visualize evolution\n",
    "    results_dir = \"evolution_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    mahalanobis_evolver.visualize_evolution(\n",
    "        logbook, \n",
    "        save_path=os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630042cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Example usage of the MetricEvaluator framework.\n",
    "    \"\"\"\n",
    "    print(\"========== Metric Evaluation Framework Demo ==========\")\n",
    "    \n",
    "    # Initialize the evaluator\n",
    "    evaluator = MetricEvaluator(random_state=42)\n",
    "    \n",
    "    # 1. Load and prepare a dataset\n",
    "    print(\"\\n1. Loading and preparing the Iris dataset...\")\n",
    "    evaluator.load_standard_dataset('iris')\n",
    "    evaluator.prepare_data('iris', test_size=0.2, scale=True)\n",
    "    \n",
    "    # 2. Add standard distance metrics\n",
    "    print(\"\\n2. Adding standard distance metrics...\")\n",
    "    evaluator.add_standard_metrics()\n",
    "    \n",
    "    # 3. Add metric learning based metrics\n",
    "    print(\"\\n3. Adding metric learning based metrics...\")\n",
    "    evaluator.add_ml_metrics()\n",
    "    \n",
    "    # 4. Add a custom evolved Mahalanobis metric (for demonstration)\n",
    "    print(\"\\n4. Adding an evolved Mahalanobis metric...\")\n",
    "    n_features = evaluator.X_train.shape[1]\n",
    "    # This is just for demonstration - in reality this would come from your\n",
    "    # evolutionary algorithm. Here we just create a weighted identity matrix.\n",
    "    evolved_matrix = np.eye(n_features)\n",
    "    # Let's make the first feature more important\n",
    "    evolved_matrix[0, 0] = 2.0\n",
    "    evaluator.add_evolved_mahalanobis(evolved_matrix)\n",
    "    \n",
    "    # 5. Evaluate all classifiers with all metrics\n",
    "    print(\"\\n5. Evaluating classifiers...\")\n",
    "    evaluator.evaluate_all_classifiers()\n",
    "    \n",
    "    # 6. Summarize results\n",
    "    print(\"\\n6. Results summary:\")\n",
    "    summary_df = evaluator.summarize_results()\n",
    "    print(summary_df)\n",
    "    \n",
    "    # 7. Plot results\n",
    "    print(\"\\n7. Generating plots...\")\n",
    "    evaluator.plot_results(metric='test_accuracy')\n",
    "    evaluator.plot_results(metric='silhouette_score')\n",
    "    \n",
    "    # 8. Visualize data transformations\n",
    "    print(\"\\n8. Visualizing data transformations...\")\n",
    "    for metric in ['euclidean', 'lmnn', 'nca', 'evolved_mahalanobis']:\n",
    "        try:\n",
    "            evaluator.visualize_data_transformation(metric, method='tsne')\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not visualize {metric}: {e}\")\n",
    "    \n",
    "    # 9. Save results\n",
    "    print(\"\\n9. Saving results...\")\n",
    "    results_file = evaluator.save_results()\n",
    "    \n",
    "    # 10. Transfer learning experiment\n",
    "    print(\"\\n10. Running transfer learning experiment...\")\n",
    "    # Load an additional dataset for transfer experiment\n",
    "    try:\n",
    "        # Try to use Wine dataset for transfer\n",
    "        print(\"  Loading Wine dataset for transfer learning...\")\n",
    "        evaluator.load_standard_dataset('wine')\n",
    "        transfer_dataset = 'wine'\n",
    "    except Exception:\n",
    "        print(\"  Falling back to using Iris dataset again for demonstration...\")\n",
    "        transfer_dataset = 'iris'  # Fallback\n",
    "    \n",
    "    # Prepare the new dataset\n",
    "    evaluator.prepare_data(transfer_dataset, test_size=0.2, scale=True)\n",
    "    \n",
    "    # Evaluate with the previously trained metrics\n",
    "    # This tests how well the metrics learned on Iris transfer to Wine\n",
    "    print(f\"  Evaluating on {transfer_dataset} dataset using metrics trained on Iris...\")\n",
    "    evaluator.evaluate_all_classifiers(['euclidean', 'lmnn', 'nca', 'evolved_mahalanobis'])\n",
    "    \n",
    "    # Summarize transfer results\n",
    "    transfer_summary = evaluator.summarize_results()\n",
    "    print(\"\\n  Transfer learning results:\")\n",
    "    print(transfer_summary[transfer_summary['Dataset'] == transfer_dataset])\n",
    "    \n",
    "    # Plot transfer results\n",
    "    evaluator.plot_results(dataset_name=transfer_dataset, metric='test_accuracy')\n",
    "    \n",
    "    print(\"\\n========== Demo Complete ==========\")\n",
    "    print(f\"Results and visualizations saved to: {os.path.abspath(evaluator.results_dir)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
